---
categories:
- ""
- ""
date: "2017-10-31T22:42:51-05:00"
description: This is a group data analytic project completed by LBS MAM2022 Study Group 9.
draft: false
image: analytic.jpeg
keywords: ""
slug: hw
title: Group Project Three
---

```{r, setup, echo=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```


```{r load-libraries, echo=FALSE}
library(tidyverse)  # load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(GGally)
library(readxl)
library(here)
library(skimr)
library(janitor)
library(broom)
library(tidyquant)
library(infer)
library(openintro)
```


# Youth Risk Behavior Surveillance

Every two years, the Centers for Disease Control and Prevention conduct the [Youth Risk Behavior Surveillance System (YRBSS)](https://www.cdc.gov/healthyyouth/data/yrbs/index.htm) survey, where it takes data from high schoolers (9th through 12th grade), to analyze health patterns.

## Load the data

This data is part of the `openintro` textbook and we can load and inspect it. There are observations on 13 different variables, some categorical and some numerical. The meaning of each variable can be found by bringing up the help file:

?yrbss

```{r}
data(yrbss)
glimpse(yrbss)
```

Before we carry on with our analysis, it's is always a good idea to check with `skimr::skim()` to get a feel for missing values, summary statistics of numerical variables, and a very rough histogram.
```{r}
skim(yrbss)
```


## Exploratory Data Analysis

We first start with analysing the `weight` of participants in kilograms. Using visualization and summary statistics, we can describe the distribution of weights:

> The distribution of weight is right(positive) skewed. 1004 observations are missed in the weight from. 

```{r, eda_on_weight}
skim(yrbss)

ggplot(data = yrbss)+
  geom_density(aes(x = weight), kernel = "gaussian") 

```

Next, consider the possible relationship between a high schooler’s weight and their physical activity. Plotting the data is a useful first step because it helps us quickly visualize trends, identify strong associations, and develop research questions.

Let’s create a new variable in the dataframe `yrbss`, called `physical_3plus` , which will be `yes` if they are physically active for at least 3 days a week, and `no` otherwise.

  
```{r, mutate_and_count}
yrbss <- yrbss %>% 
  # count(physically_active_7d) %>% 
  mutate(yrbss,physical_3plus = ifelse(physically_active_7d >= 3,"yes","no"))


yrbss_count <- yrbss %>% 
  count(physical_3plus) %>% 
  mutate(perc = n/sum(n))
yrbss_count
```

There is a slightly positive relationship between thse two variables. I expected that there would be positive relationship between physical_3plus and weight because if people did more execrises per week, they would have more muscles which would be much heavier that fat.

```{r, boxplot}
ybrss_physical3minus <- 
  filter(yrbss, physical_3plus == "no")
# ybrss_physical3minus
# yrbss
ggplot(data = yrbss,aes(x = physical_3plus, y =weight))+
  geom_boxplot()

```

## Confidence Interval

Boxplots show how the medians of the two distributions compare, but we can also compare the means of the distributions using either a confidence interval or a hypothesis test. Note that when we calculate the mean, SD, etc. weight in these groups using the mean function, we must ignore any missing values by setting the `na.rm = TRUE`.

```{r, ci_using_formulas}
# t.test(weight ~ physical_3plus, data = yrbss)
yrbss %>% 
  group_by(physical_3plus) %>% 
  summarise(mean_weight = mean(weight,na.rm = TRUE))
```

There is an observed difference of about 1.77kg (68.44 - 66.67), and we notice that the two confidence intervals do not overlap. It seems that the difference is at least 95% statistically significant. Let us also conduct a hypothesis test.

## Hypothesis test with formula

The null hypotheses : The mean weights of people who exercise at least times a week is the same as the mean weights of people who don't.
The alternative hypothesesz: The mean weights of people who exercise at least times a week is significantly different from the mean weights of people who don't.

```{r, t_test_using_R}
t.test(weight ~ physical_3plus, data = yrbss)
```

## Hypothesis test with `infer`


Next, we will introduce a new function, `hypothesize`, that falls into the infer workflow. We will use this method for conducting hypothesis tests.

But first, we need to initialize the test, which we will save as `obs_diff`.

```{r, calc_obs_difference}
obs_diff <- yrbss %>%
  specify(weight ~ physical_3plus) %>%
  calculate(stat = "diff in means", order = c("yes", "no"))
obs_diff
```

Notice how we can use the functions specify and calculate again like we did for calculating confidence intervals. Here, though, the statistic we are searching for is the difference in means, with the order being yes - no != 0.

After we have initialized the test, we need to simulate the test on the null distribution, which we will save as null.


```{r, hypothesis_testing_using_infer_package}

null_dist <- yrbss %>%
  # specify variables
  specify(weight ~ physical_3plus) %>%
  
  # assume independence, i.e, there is no difference
  hypothesize(null = "independence") %>%
  
  # generate 1000 reps, of type "permute"
  generate(reps = 1000, type = "permute") %>%
  
  # calculate statistic of difference, namely "diff in means"
  calculate(stat = "diff in means", order = c("yes", "no"))
null_dist
```


Here, `hypothesize` is used to set the null hypothesis as a test for independence, i.e., that there is no difference between the two population means. In one sample cases, the null argument can be set to *point* to test a hypothesis relative to a point estimate.

Also, note that the `type` argument within generate is set to permute, which is the argument when generating a null distribution for a hypothesis test.

We can visualize this null distribution with the following code:

```{r}
ggplot(data = null_dist, aes(x = stat)) +
  geom_histogram()
```


Now that the test is initialized and the null distribution formed, we can visualise to see how many of these null permutations have a difference of at least `obs_stat` of `r obs_diff %>% pull() %>% round(2)`?

We can also calculate the p-value for our hypothesis test using the function `infer::get_p_value()`.

```{r}

null_dist %>% visualize() +
  shade_p_value(obs_stat = obs_diff, direction = "two-sided")

null_dist %>%
  infer::get_p_value(obs_stat = obs_diff, direction = "two_sided")

```

This the standard workflow for performing hypothesis tests.

# IMDB ratings: Differences between directors

We would like to explore whether the mean IMDB rating for Steven Spielberg and Tim Burton are the same or not by running a hpothesis test.

We can load the data and examine its structure

```{r load-movies-data}
movies <- read_csv(here::here("data", "movies.csv"))
glimpse(movies)
```

```{r}
ci_data <- movies %>% 
  filter(director %in% c("Steven Spielberg","Tim Burton")) %>% 
  group_by(director) %>% 
  summarise(mean_rating = mean(rating),
            count = n(),
            margin_of_error = qt(0.975, count-1)*sd(rating)/sqrt(count),
            rating_lower = mean_rating - margin_of_error,
            rating_upper = mean_rating + margin_of_error)

ggplot(ci_data,aes(x = mean_rating, y = reorder(director, desc(director)), colour = director)) + 
  geom_point(size = 3) +
  geom_errorbar(aes(xmin = rating_lower, xmax = rating_upper), width = 0.2, size = 1) +
  geom_rect(aes(xmin=max(rating_lower), xmax=min(rating_upper), ymin=0, ymax=Inf), color='grey', alpha=0.2) +
  geom_text(aes(label = round(mean_rating, digits = 2), x = mean_rating), size = 6, colour = "black", nudge_y = 0.15)+ 
  geom_text(aes(label = round(rating_lower, digits = 2), x = rating_lower), size = 4, colour = "black",nudge_y = 0.15) +
  geom_text(aes(label = round(rating_upper, digits = 2), x = rating_upper), size = 4, colour = "black",nudge_y = 0.15) +
  labs(title = "Do Spielberg and Burton have the same mean IMDB ratings?", subtitle = "95% confidence intervals overlap" , x = "Mean IMDB Rating", y = " ") + theme_bw() + theme(legend.position = "none") +
  NULL
```


# Omega Group plc- Pay Discrimination


At the last board meeting of Omega Group Plc., the headquarters of a large multinational company, the issue was raised that women were being discriminated in the company, in the sense that the salaries were not the same for male and female executives. A quick analysis of a sample of 50 employees (of which 24 men and 26 women) revealed that the average salary for men was about 8,700 higher than for women. This seemed like a considerable difference, so it was decided that a further analysis of the company salaries was warranted. 

The objective is to find out whether there is indeed a significant difference between the salaries of men and women, and whether the difference is due to discrimination or whether it is based on another, possibly valid, determining factor. 

## Loading the data


```{r load_omega_data}
omega <- read_csv(here::here("data", "omega.csv"))
glimpse(omega) # examine the data frame
```

## Relationship Salary - Gender ?

The data frame `omega`  contains the salaries for the sample of 50 executives in the company. Can we conclude that there is a significant difference between the salaries of the male and female executives?

Note that we can perform different types of analyses, and check whether they all lead to the same conclusion 

.	Confidence intervals
.	Hypothesis testing
.	Correlation analysis
.	Regression


Calculate summary statistics on salary by gender. Also, create and print a dataframe where, for each gender, we show the mean, SD, sample size, the t-critical, the SE, the margin of error, and the low/high endpoints of a 95% condifence interval

```{r, confint_single_valiables}
# Summary Statistics of salary by gender
mosaic::favstats (salary ~ gender, data=omega)

# Dataframe with two rows (male-female) and having as columns gender, mean, SD, sample size, 
# the t-critical value, the standard error, the margin of error, 
# and the low/high endpoints of a 95% condifence interval


```

We can also run a hypothesis testing, assuming as a null hypothesis that the mean difference in salaries is zero, or that, on average, men and women make the same amount of money.

```{r, hypothesis_testing}
# hypothesis testing using t.test() 
t.test(salary ~ gender, data=omega)

# hypothesis testing using infer package
obs_diff_2 <- omega %>%
  specify(salary ~ gender) %>%
  calculate(stat = "diff in means", order = c("female", "male"))

obs_diff_2

null_dist_2 <- omega %>%
  # specify variables
  specify(salary ~ gender) %>%
  
  # assume independence, i.e, there is no difference
  hypothesize(null = "independence") %>%
  
  # generate 1000 reps, of type "permute"
  generate(reps = 1000, type = "permute") %>%
  
  # calculate statistic of difference, namely "diff in means"
  calculate(stat = "diff in means", order = c("female", "male"))

null_dist_2

null_dist_2 %>% visualize()


```

```{r}
ggplot(data = null_dist_2, aes(x = stat)) +
  geom_histogram()

null_dist_2 %>% visualize() +
  shade_p_value(obs_stat = obs_diff_2, direction = "two-sided")

null_dist_2 %>%
  infer::get_p_value(obs_stat = obs_diff_2, direction = "two_sided")
```

According to our calculation by t.test, our p-value for the hypothesis test is 0.0001651, which is smaller than 0.05 and hence statistically significant. The p-value we retrieved from our simulations with the infer package is also infinitesmal and statistically significant. There is strong evidence against the null hypothesis and the -8696.29 years (64542.84-73239.13) of difference we estimated in our sample means is really different from zero, therefore there is a significant difference. 

We can safely conclude the salary levels of male executives is, on average, 8696.29 units more than female counterparts. 

## Relationship Experience - Gender?

At the board meeting, someone raised the issue that there was indeed a substantial difference between male and female salaries, but that this was attributable to other reasons such as differences in experience. A questionnaire send out to the 50 executives in the sample reveals that the average experience of the men is approximately 21 years, whereas the women only have about 7 years experience on average (see table below).

```{r, experience_stats}
# Summary Statistics of salary by gender
favstats (experience ~ gender, data=omega)

```

Based on this evidence, can we conclude that there is a significant difference between the experience of the male and female executives? 

```{r}
# hypothesis testing using t.test() 
t.test(experience ~ gender, data=omega)

# hypothesis testing using infer package
obs_diff_3 <- omega %>%
  specify(experience ~ gender) %>%
  calculate(stat = "diff in means", order = c("female", "male"))

obs_diff_3

null_dist_3 <- omega %>%
  # specify variables
  specify(experience ~ gender) %>%
  
  # assume independence, i.e, there is no difference
  hypothesize(null = "independence") %>%
  
  # generate 1000 reps, of type "permute"
  generate(reps = 1000, type = "permute") %>%
  
  # calculate statistic of difference, namely "diff in means"
  calculate(stat = "diff in means", order = c("female", "male"))

null_dist_3

null_dist_3 %>% visualize()
```

```{r}
ggplot(data = null_dist_3, aes(x = stat)) +
  geom_histogram()

null_dist_3 %>% visualize() +
  shade_p_value(obs_stat = obs_diff_3, direction = "two-sided")

null_dist_3 %>%
  infer::get_p_value(obs_stat = obs_diff_3, direction = "two_sided")
```

According to our calculation by t.test, our p-value for the hypothesis test is 1.225e-05, which is smaller than 0.05 and hence statistically significant. The p-value we retrieved from our simulations with the infer package is also infinitesmal and statistically significant. There is strong evidence against the null hypothesis and the -13.7 years (7.38-21.13) of difference we estimated in our sample means is really different from zero, therefore there is a significant difference. 

We can safely conclude the experience levels of male executives is, on average, 13.7 years more than female counterparts. 

## Relationship Salary - Experience ?

Someone at the meeting argues that clearly, a more thorough analysis of the relationship between salary and experience is required before any conclusion can be drawn about whether there is any gender-based salary discrimination in the company.

Analyse the relationship between salary and experience. Draw a scatterplot to visually inspect the data


```{r, salary_exp_scatter}
ggplot(omega, aes(x = experience, y = salary)) + geom_point() +geom_smooth(se = FALSE)
```
In general, there is a moderate positive relationship between executives' salary and experience. However, the strength of this relationship becomes weaker as the experience level increases, suggesting that experience may be an important factor influencing the salary levels for early-careers and not so much important for the already experienced professionals. 

## Check correlations between the data
We can use `GGally:ggpairs()` to create a scatterplot and correlation matrix. Essentially, we change the order our variables will appear in and have the dependent variable (Y), salary, as last in our list. We then pipe the dataframe to `ggpairs()` with `aes` arguments to colour by `gender` and make ths plots somewhat transparent (`alpha  = 0.3`).

```{r, ggpairs}
omega %>% 
  select(gender, experience, salary) %>% #order variables they will appear in ggpairs()
  ggpairs(aes(colour=gender, alpha = 0.3))+
  theme_bw()
```

The salary vs experience scatterplot shows that female executives in this sample are more concentrated on the left side of the plot, which means that generally they have lower experience levels than their male counterparts. Given the 0.812 correlation between salary and experience levels for female executives, which is higher than the 0.661 correlation for males, it is reasonable that we see a stronger relationship between salary and experience levels for early career professionals. 

However, we cannot safely conclude whether this difference in salary level between female and male executives is due to gender difference or difference in experience levels. More research is required to investigate the causal relationship on salary levels and the two different factors. 


# Challenge 1: Brexit plot

Using our data manipulation and visualisation skills, we will illustrate how political affliation is translated to Brexit voting.

```{r brexit_challenge, echo=FALSE, out.width="100%"}
data_brex_results <- read_csv(here::here('data','brexit_results.csv'))

skim(data_brex_results)

brex_results_long <- data_brex_results %>% 
  pivot_longer(cols = 2:5, #columns 3 to 5
               names_to = "indicator",
               values_to = "value")

brex_results_long %>% 
  # filter( %in% c("France", "Spain", "Italy", "United Kingdom", "Thailand", "China")) %>%
  ggplot(aes(x=value, y = leave_share, colour=indicator))+
  scale_color_manual(values = c("#0087dc","#d50000","#FDBB30","#EFE600"))+
  # geom_line(aes(x = value,y = leave_share,color = indicator),size = 0.5)+
  geom_point(size= 0.7)+
  geom_smooth(method = 'lm', formula =y~x)+
  coord_fixed(ratio=0.5)+
  # facet_grid(rows = vars(indicator),
             # cols = vars(country), 
             # scales = "free")+
  # theme_bw()+
  # theme(legend.position = "none")+
  # scale_y_continuous(labels = scales::label_percent())+
  labs(
    title = "How political affliation translated to Brexit Voting",
    x = "Party % in the UK 2015 general election",
    y = "Leave % in the 2016 Brexit reference"
  )+
theme(legend.position="bottom")
ggsave("brexresultslong.jpg")
# 

```

# Challenge 2:GDP components over time and among countries

At the risk of oversimplifying things, the main components of gross domestic product, GDP are personal consumption (C), business investment (I), government spending (G) and net exports (exports - imports). You can read more about GDP and the different approaches in calculating at the [Wikipedia GDP page](https://en.wikipedia.org/wiki/Gross_domestic_product).

The GDP data we will look at is from the [United Nations' National Accounts Main Aggregates Database](https://unstats.un.org/unsd/snaama/Downloads), which contains estimates of total GDP and its components for all countries from 1970 to today. We will look at how GDP and its components have changed over time, and compare different countries and how much each component contributes to that country's GDP. The file we will work with is [GDP and its breakdown at constant 2010 prices in US Dollars](http://unstats.un.org/unsd/amaapi/api/file/6).

```{r read_GDP_data}

UN_GDP_data  <-  read_excel(here::here("data", "Download-GDPconstant-USD-countries.xls"), # Excel filename
                sheet="Download-GDPconstant-USD-countr", # Sheet name
                skip=2) # Number of rows to skip

```

The first thing we need to do is to tidy the data, as it is in wide format and we must make it into long, tidy format. Please express all figures in billions (divide values by `1e9`, or $10^9$), and we want to rename the indicators into something shorter.

```{r reshape_GDP_data}

tidy_GDP_data  <-  UN_GDP_data %>% 
  pivot_longer(cols = 4:51, names_to = "Year", values_to = "Value") %>%
  mutate(Value = Value/(10^9))
glimpse(tidy_GDP_data)


# Let us compare GDP components for these 3 countries
country_list <- c("United States","India", "Germany")
```

Next, we produce a plot of GDP components over time.

```{r}
three_country_data <- tidy_GDP_data %>% 
  filter(Country %in% country_list) %>% 
  filter(IndicatorName %in% c("Gross capital formation" ,"Exports of goods and services" ,"General government final consumption expenditure" , "Household consumption expenditure (including Non-profit institutions serving households)", "Imports of goods and services")) %>% 
  mutate(Year = as.numeric(Year)) %>% 
  group_by(Year)
        
ggplot(three_country_data, mapping = aes(x=Year, y=Value , colour=IndicatorName)) +geom_line() + 
  facet_wrap(~Country) +
  labs(title = "GDP components over time", subtitle = "In constant 2010 USD", colour = "Components of GDP", x = element_blank(), y = "Billion US$") + 
  scale_colour_discrete(breaks = c("Gross capital formation" ,"Exports of goods and services" ,"General government final consumption expenditure" , "Household consumption expenditure (including Non-profit institutions serving households)", "Imports of goods and services"), labels = c("Gross capital formation" ,"Exports" ,"Government expenditure" , "Household expenditure", "Imports") ) +
  theme_bw()
```

Afterwards, recall that GDP is the sum of Household Expenditure (Consumption *C*), Gross Capital Formation (business investment *I*), Government Expenditure (G) and Net Exports (exports - imports).

```{r}
wide_GDP_data <- tidy_GDP_data %>% 
  pivot_wider(names_from = "IndicatorName", values_from  = "Value") %>% 
  clean_names()

wide_GDP_data %>% 
  mutate(GDP_calculated = gross_capital_formation + general_government_final_consumption_expenditure+ household_consumption_expenditure_including_non_profit_institutions_serving_households+ exports_of_goods_and_services - imports_of_goods_and_services) %>% 
  select(country, year, GDP_calculated, gross_domestic_product_gdp)

```

```{r gdp2, echo=FALSE, out.width="100%"}
knitr::include_graphics(here::here("images", "gdp2.png"), error = FALSE)
```

This chart shows the separate trends of the proportions of 4 components of GDP. We can see that in terms of household expenditure, which is the biggest component of all three countries' GDP, its proportion is relatively stable for Germany and United States and decreasing for India. Germany has the most stable household expediture level between 50% and 60%. The United States' household expenditure exhibits a slightly increasing trend from 60% to 70%. India's household expenditure has a sharp decreasing trend since 1980. Such differences may be due to the fact that Germany and the US are both developed countries and are already stable in development speed. 

Gross capital formation, which indicates the level of investment slightly decreases over time in Germany, slightly increased in the US, and increased significantly in India especially since 2000. Hence, we can reasonably speculate that India might have gone through a period of rapid development, with households decreasing their consumption, saving more money, and initiating more investments. 

Government expenditure has been stable in Germany and India, but exhibits a decreasing trend for the US, probably due to a tightening government budget and increasing level of debt. It is worth noting that India's gross capital formation proportion in GDP has always beeen 10-30% above the government expenditure proportion level, while these two components have been competing for Germany and the US, both fluctuating at around 20%. 

Net exports have been stable for India and the US before 2000 and both experienced a decrease of about 5% after then. Germany's net export proportion level has also been stable until 2000 and experienced an increase afterwards, which suggests that it became more of an exporter than importer than it was before 2000. 

Collaborators: Study Group 9




